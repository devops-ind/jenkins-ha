#!/bin/bash
# Unified Jenkins Data Management Script for {{ item.team_name }}
# Supports flexible backup, sync, and combined operations
# Generated by Ansible jenkins-master-v2 role

set -euo pipefail

# Script configuration
TEAM_NAME="{{ item.team_name }}"
ACTIVE_ENV="{{ item.active_environment | default('blue') }}"
CONTAINER_NAME="jenkins-${TEAM_NAME}-${ACTIVE_ENV}"
STORAGE_PATH="{{ storage_path }}"
STORAGE_TYPE="{{ storage_type }}"
TEAM_STORAGE_PATH="${STORAGE_PATH}/${TEAM_NAME}"

# Backup configuration
BACKUP_ENABLED="{{ backup_enabled | default(false) }}"
BACKUP_METHOD="{{ backup_method | default('tar') }}"
BACKUP_LOCAL_DIR="{{ backup_local_dir | default('/var/backups/jenkins') }}"
BACKUP_RETENTION_DAYS="{{ backup_daily_retention | default(7) }}"
BACKUP_COMPRESSION="{{ backup_compression | default('gzip') }}"

# Unified operation configuration
DEFAULT_OPERATION_MODE="{{ default_operation_mode | default('sync-only') }}"
BACKUP_BEFORE_SYNC="{{ backup_before_sync | default(false) }}"
SYNC_VERIFICATION_ENABLED="{{ sync_verification_enabled | default(true) }}"
BACKUP_VERIFICATION_ENABLED="{{ backup_verification_enabled | default(true) }}"

# Runtime variables
OPERATION_MODE="$DEFAULT_OPERATION_MODE"
TARGET_ENV=""
BACKUP_TARGET="local"
RETENTION_DAYS="$BACKUP_RETENTION_DAYS"
SYNC_METHOD="{{ sync_method | default('rsync') }}"
LOG_FILE="/var/log/jenkins-${TEAM_NAME}-unified.log"
VERBOSE=false
DRY_RUN=false

# Data types to process
DATA_TYPES=("jobs" "workspace" "builds" "userContent" "secrets")

# Logging functions
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [INFO] $*" | tee -a "$LOG_FILE"
}

warn() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [WARN] $*" | tee -a "$LOG_FILE"
}

error() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [ERROR] $*" | tee -a "$LOG_FILE"
}

debug() {
    if [[ "$VERBOSE" == "true" ]]; then
        echo "[$(date '+%Y-%m-%d %H:%M:%S')] [DEBUG] $*" | tee -a "$LOG_FILE"
    fi
}

# Usage function
usage() {
    cat << EOF
Usage: $0 [OPTIONS]

Unified Jenkins Data Management Script for ${TEAM_NAME}

OPERATION MODES:
    --sync-only              Perform synchronization only (default)
    --backup-only            Perform backup only
    --sync-and-backup        Perform both sync and backup operations
    --backup-then-sync       Backup first, then sync
    --sync-then-backup       Sync first, then backup

SYNC OPTIONS:
    --target {blue|green|shared}  Sync target (default: shared)
    --sync-method {rsync|cp}      Sync method (default: rsync)

BACKUP OPTIONS:
    --backup-to {local|nfs}       Backup storage location (default: local)
    --retention {days}            Backup retention in days (default: ${BACKUP_RETENTION_DAYS})
    --backup-method {tar|borg}    Backup method (default: ${BACKUP_METHOD})

GENERAL OPTIONS:
    --dry-run                     Show what would be done without executing
    --verbose                     Enable verbose logging
    --verify                      Enable verification (default: enabled)
    --no-verify                   Disable verification
    --help                        Show this help message

EXAMPLES:
    $0                                    # Default: sync to shared storage
    $0 --sync-and-backup                  # Sync to shared and backup locally
    $0 --backup-only --retention 14       # Backup only with 14-day retention
    $0 --target green --sync-only         # Sync from ${ACTIVE_ENV} to green environment
    $0 --backup-then-sync --verbose       # Backup first, then sync with verbose output
    $0 --sync-then-backup --dry-run       # Preview sync then backup operations

OPERATION FLOW:
    sync-only:         Container → Target
    backup-only:       Container → Backup Storage
    sync-and-backup:   Container → Target & Backup Storage (parallel)
    backup-then-sync:  Container → Backup Storage → Target
    sync-then-backup:  Container → Target → Backup Storage

EOF
}

# Parse command line arguments
parse_arguments() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            --sync-only)
                OPERATION_MODE="sync-only"
                shift
                ;;
            --backup-only)
                OPERATION_MODE="backup-only"
                shift
                ;;
            --sync-and-backup)
                OPERATION_MODE="sync-and-backup"
                shift
                ;;
            --backup-then-sync)
                OPERATION_MODE="backup-then-sync"
                shift
                ;;
            --sync-then-backup)
                OPERATION_MODE="sync-then-backup"
                shift
                ;;
            --target)
                TARGET_ENV="$2"
                shift 2
                ;;
            --backup-to)
                BACKUP_TARGET="$2"
                shift 2
                ;;
            --retention)
                RETENTION_DAYS="$2"
                shift 2
                ;;
            --backup-method)
                BACKUP_METHOD="$2"
                shift 2
                ;;
            --sync-method)
                SYNC_METHOD="$2"
                shift 2
                ;;
            --dry-run)
                DRY_RUN=true
                shift
                ;;
            --verbose)
                VERBOSE=true
                shift
                ;;
            --verify)
                SYNC_VERIFICATION_ENABLED=true
                BACKUP_VERIFICATION_ENABLED=true
                shift
                ;;
            --no-verify)
                SYNC_VERIFICATION_ENABLED=false
                BACKUP_VERIFICATION_ENABLED=false
                shift
                ;;
            --help)
                usage
                exit 0
                ;;
            *)
                error "Unknown option: $1"
                usage
                exit 1
                ;;
        esac
    done
}

# Validate configuration and arguments
validate_configuration() {
    debug "Validating configuration..."
    
    # Validate operation mode
    case "$OPERATION_MODE" in
        sync-only|backup-only|sync-and-backup|backup-then-sync|sync-then-backup)
            debug "Operation mode: $OPERATION_MODE"
            ;;
        *)
            error "Invalid operation mode: $OPERATION_MODE"
            return 1
            ;;
    esac
    
    # Validate target environment for sync operations
    if [[ "$OPERATION_MODE" == *"sync"* ]] && [[ -n "$TARGET_ENV" ]]; then
        case "$TARGET_ENV" in
            blue|green)
                if [[ "$TARGET_ENV" == "$ACTIVE_ENV" ]]; then
                    warn "Target environment ($TARGET_ENV) is same as active environment ($ACTIVE_ENV)"
                    return 1
                fi
                debug "Blue-green sync target: $TARGET_ENV"
                ;;
            shared)
                debug "Shared storage sync target"
                ;;
            *)
                error "Invalid sync target: $TARGET_ENV. Must be 'blue', 'green', or 'shared'"
                return 1
                ;;
        esac
    fi
    
    # Validate backup configuration
    if [[ "$OPERATION_MODE" == *"backup"* ]]; then
        if [[ "$BACKUP_TARGET" != "local" && "$BACKUP_TARGET" != "nfs" ]]; then
            error "Invalid backup target: $BACKUP_TARGET. Must be 'local' or 'nfs'"
            return 1
        fi
        
        if [[ "$BACKUP_METHOD" != "tar" && "$BACKUP_METHOD" != "borg" ]]; then
            error "Invalid backup method: $BACKUP_METHOD. Must be 'tar' or 'borg'"
            return 1
        fi
        
        if [[ ! "$RETENTION_DAYS" =~ ^[0-9]+$ ]] || [[ "$RETENTION_DAYS" -lt 1 ]]; then
            error "Invalid retention period: $RETENTION_DAYS. Must be a positive number"
            return 1
        fi
        
        debug "Backup configuration: method=$BACKUP_METHOD, target=$BACKUP_TARGET, retention=${RETENTION_DAYS}d"
    fi
    
    return 0
}

# Check prerequisites
check_prerequisites() {
    debug "Checking prerequisites..."
    
    local prerequisites_ok=true
    
    # Check if sync operations are possible
    if [[ "$OPERATION_MODE" == *"sync"* ]]; then
        # Check container status for sync operations
        if [[ -z "$TARGET_ENV" || "$TARGET_ENV" == "shared" ]]; then
            if ! docker ps --filter "name=${CONTAINER_NAME}" | grep -q "${CONTAINER_NAME}"; then
                error "Container ${CONTAINER_NAME} not running, cannot perform sync operations"
                prerequisites_ok=false
            fi
        fi
        
        # Check storage accessibility
        if [[ -z "$TARGET_ENV" || "$TARGET_ENV" == "shared" ]]; then
            if [[ ! -d "$STORAGE_PATH" ]] || [[ ! -w "$STORAGE_PATH" ]]; then
                error "Storage not accessible at $STORAGE_PATH"
                prerequisites_ok=false
            fi
        fi
        
        # Check blue-green volume accessibility
        if [[ -n "$TARGET_ENV" && "$TARGET_ENV" != "shared" ]]; then
            local source_volume="jenkins-${TEAM_NAME}-${ACTIVE_ENV}-home"
            local target_volume="jenkins-${TEAM_NAME}-${TARGET_ENV}-home"
            
            if ! docker volume inspect "${source_volume}" >/dev/null 2>&1; then
                error "Source volume ${source_volume} does not exist"
                prerequisites_ok=false
            fi
            
            if ! docker volume inspect "${target_volume}" >/dev/null 2>&1; then
                error "Target volume ${target_volume} does not exist"
                prerequisites_ok=false
            fi
        fi
    fi
    
    # Check backup prerequisites
    if [[ "$OPERATION_MODE" == *"backup"* ]]; then
        # Check backup directory accessibility
        local backup_dir="${BACKUP_LOCAL_DIR}/${TEAM_NAME}"
        if [[ ! -d "$backup_dir" ]]; then
            debug "Creating backup directory: $backup_dir"
            if [[ "$DRY_RUN" != "true" ]]; then
                mkdir -p "$backup_dir" || {
                    error "Failed to create backup directory: $backup_dir"
                    prerequisites_ok=false
                }
            fi
        elif [[ ! -w "$backup_dir" ]]; then
            error "Backup directory not writable: $backup_dir"
            prerequisites_ok=false
        fi
        
        # Check available disk space
        local available_space
        available_space=$(df "$backup_dir" | awk 'NR==2 {print $4}')
        local min_space_kb=$((1024 * 1024))  # 1GB minimum
        
        if [[ "$available_space" -lt "$min_space_kb" ]]; then
            error "Insufficient disk space for backup. Available: $(($available_space/1024))MB, Required: 1GB"
            prerequisites_ok=false
        fi
    fi
    
    if [[ "$prerequisites_ok" != "true" ]]; then
        error "Prerequisites check failed"
        return 1
    fi
    
    debug "Prerequisites check passed"
    return 0
}

# Sync functions
perform_sync_to_shared() {
    log "[SYNC] Starting sync to shared storage..."
    
    if [[ "$DRY_RUN" == "true" ]]; then
        log "[DRY RUN] Would sync ${TEAM_NAME} data from ${CONTAINER_NAME} to ${TEAM_STORAGE_PATH}"
        return 0
    fi
    
    # Ensure team directories exist in storage
    mkdir -p "${TEAM_STORAGE_PATH}"/{jobs,workspace,builds,userContent,secrets}
    
    local sync_success=0
    local sync_total=${{ '{#' }}DATA_TYPES[@]}
    
    for data_type in "${DATA_TYPES[@]}"; do
        debug "Syncing ${data_type}..."
        
        local container_path="/var/jenkins_home/${data_type}"
        local storage_path="${TEAM_STORAGE_PATH}/${data_type}"
        
        # Check if source exists in container
        if ! docker exec "${CONTAINER_NAME}" test -d "${container_path}" 2>/dev/null; then
            debug "Source ${container_path} does not exist in container, skipping ${data_type}"
            continue
        fi
        
        # Perform sync based on method
        case "$SYNC_METHOD" in
            "rsync"|"cp")
                if docker cp "${CONTAINER_NAME}:${container_path}/." "${storage_path}/"; then
                    # Set proper ownership
                    chown -R {{ jenkins_user }}:{{ jenkins_group }} "${storage_path}"
                    debug "[SUCCESS] Successfully synced ${data_type}"
                    ((sync_success++))
                else
                    error "[ERROR] Failed to sync ${data_type}"
                fi
                ;;
        esac
        
        # Update timestamp marker
        docker exec "${CONTAINER_NAME}" touch "${container_path}/.last_sync" 2>/dev/null || true
    done
    
    if [[ $sync_success -eq $sync_total ]]; then
        log "[SUCCESS] Shared storage sync completed successfully (${sync_success}/${sync_total})"
        return 0
    else
        error "[WARNING] Partial shared storage sync completed (${sync_success}/${sync_total})"
        return 1
    fi
}

perform_sync_to_bluegreen() {
    log "[SYNC] Starting blue-green sync: ${ACTIVE_ENV} -> ${TARGET_ENV}..."
    
    if [[ "$DRY_RUN" == "true" ]]; then
        log "[DRY RUN] Would sync from ${ACTIVE_ENV} environment to ${TARGET_ENV} environment"
        return 0
    fi
    
    local source_volume="jenkins-${TEAM_NAME}-${ACTIVE_ENV}-home"
    local target_volume="jenkins-${TEAM_NAME}-${TARGET_ENV}-home"
    local temp_container="unified-sync-temp-${TEAM_NAME}-$$"
    
    # Create temporary container with both volumes mounted
    docker run --rm -d \
        --name "${temp_container}" \
        -v "${source_volume}:/source" \
        -v "${target_volume}:/target" \
        alpine:latest sleep 300 || {
        error "Failed to create temporary sync container"
        return 1
    }
    
    local sync_success=0
    local sync_total=${{ '{#' }}DATA_TYPES[@]}
    
    for data_type in "${DATA_TYPES[@]}"; do
        debug "Blue-green syncing ${data_type}..."
        
        if docker exec "${temp_container}" test -d "/source/${data_type}"; then
            # Create target directory and sync data
            docker exec "${temp_container}" mkdir -p "/target/${data_type}" && \
            docker exec "${temp_container}" sh -c "
                cd /source/${data_type} && 
                find . -type f -exec cp -p {} /target/${data_type}/{} \\; 2>/dev/null || true &&
                find . -type d -exec mkdir -p /target/${data_type}/{} \\; 2>/dev/null || true
            " && {
                debug "[SUCCESS] Successfully synced ${data_type}"
                ((sync_success++))
            } || {
                error "[ERROR] Failed to sync ${data_type}"
            }
        else
            debug "Source ${data_type} does not exist, skipping"
            ((sync_success++))  # Count as success for missing directories
        fi
    done
    
    # Clean up temporary container
    docker stop "${temp_container}" >/dev/null 2>&1
    
    if [[ $sync_success -eq $sync_total ]]; then
        log "[SUCCESS] Blue-green sync completed successfully (${sync_success}/${sync_total})"
        return 0
    else
        error "[WARNING] Partial blue-green sync completed (${sync_success}/${sync_total})"
        return 1
    fi
}

# Backup functions
perform_backup() {
    log "[BACKUP] Starting backup operation..."
    
    local backup_dir="${BACKUP_LOCAL_DIR}/${TEAM_NAME}"
    local timestamp=$(date '+%Y%m%d_%H%M%S')
    local backup_name="${TEAM_NAME}_${ACTIVE_ENV}_${timestamp}"
    
    if [[ "$DRY_RUN" == "true" ]]; then
        log "[DRY RUN] Would create backup: ${backup_dir}/${backup_name}"
        return 0
    fi
    
    mkdir -p "$backup_dir"
    
    case "$BACKUP_METHOD" in
        "tar")
            perform_tar_backup "$backup_dir" "$backup_name"
            ;;
        "borg")
            perform_borg_backup "$backup_dir" "$backup_name"
            ;;
        *)
            error "Unknown backup method: $BACKUP_METHOD"
            return 1
            ;;
    esac
}

perform_tar_backup() {
    local backup_dir="$1"
    local backup_name="$2"
    local backup_file="${backup_dir}/${backup_name}.tar"
    
    debug "Creating tar backup: $backup_file"
    
    # Add compression if enabled
    if [[ "$BACKUP_COMPRESSION" == "gzip" ]]; then
        backup_file="${backup_file}.gz"
        local tar_options="czf"
    else
        local tar_options="cf"
    fi
    
    # Create temporary directory for container data extraction
    local temp_dir="/tmp/jenkins-backup-${TEAM_NAME}-$$"
    mkdir -p "$temp_dir"
    
    local backup_success=0
    local backup_total=${{ '{#' }}DATA_TYPES[@]}
    
    # Extract data from container
    for data_type in "${DATA_TYPES[@]}"; do
        local container_path="/var/jenkins_home/${data_type}"
        local temp_path="${temp_dir}/${data_type}"
        
        if docker exec "${CONTAINER_NAME}" test -d "${container_path}" 2>/dev/null; then
            debug "Backing up ${data_type}..."
            if docker cp "${CONTAINER_NAME}:${container_path}" "$temp_path"; then
                ((backup_success++))
            else
                error "Failed to extract ${data_type} from container"
            fi
        else
            debug "Skipping missing ${data_type}"
            ((backup_success++))  # Count as success for missing directories
        fi
    done
    
    # Create tar archive
    if [[ $backup_success -eq $backup_total ]]; then
        if tar $tar_options "$backup_file" -C "$temp_dir" .; then
            log "[SUCCESS] Backup created successfully: $backup_file"
            
            # Verify backup if enabled
            if [[ "$BACKUP_VERIFICATION_ENABLED" == "true" ]]; then
                verify_tar_backup "$backup_file"
            fi
            
            # Set proper ownership
            chown {{ jenkins_user }}:{{ jenkins_group }} "$backup_file"
            
            # Cleanup old backups
            cleanup_old_backups "$backup_dir"
            
            # Cleanup temporary directory
            rm -rf "$temp_dir"
            
            return 0
        else
            error "Failed to create tar backup"
            rm -rf "$temp_dir"
            return 1
        fi
    else
        error "Failed to extract all data types for backup"
        rm -rf "$temp_dir"
        return 1
    fi
}

perform_borg_backup() {
    local backup_dir="$1"
    local backup_name="$2"
    
    # Borg backup implementation would go here
    # This is a placeholder for future borg integration
    warn "Borg backup not yet implemented, falling back to tar"
    perform_tar_backup "$backup_dir" "$backup_name"
}

# Verification functions
verify_tar_backup() {
    local backup_file="$1"
    
    debug "Verifying backup integrity: $backup_file"
    
    if [[ "$backup_file" == *.gz ]]; then
        if tar -tzf "$backup_file" >/dev/null 2>&1; then
            debug "[SUCCESS] Backup verification passed"
            return 0
        else
            error "[ERROR] Backup verification failed"
            return 1
        fi
    else
        if tar -tf "$backup_file" >/dev/null 2>&1; then
            debug "[SUCCESS] Backup verification passed"
            return 0
        else
            error "[ERROR] Backup verification failed"
            return 1
        fi
    fi
}

verify_sync_operation() {
    debug "Verifying sync operation..."
    
    if [[ -n "$TARGET_ENV" && "$TARGET_ENV" != "shared" ]]; then
        # Blue-green sync verification
        local source_volume="jenkins-${TEAM_NAME}-${ACTIVE_ENV}-home"
        local target_volume="jenkins-${TEAM_NAME}-${TARGET_ENV}-home"
        
        # Basic verification - check if target volume has expected data
        if docker run --rm -v "${target_volume}:/target" alpine:latest test -d "/target/jobs"; then
            debug "[SUCCESS] Blue-green sync verification passed"
            return 0
        else
            error "[ERROR] Blue-green sync verification failed"
            return 1
        fi
    else
        # Shared storage sync verification
        if [[ -d "${TEAM_STORAGE_PATH}/jobs" ]]; then
            debug "[SUCCESS] Shared storage sync verification passed"
            return 0
        else
            error "[ERROR] Shared storage sync verification failed"
            return 1
        fi
    fi
}

# Cleanup functions
cleanup_old_backups() {
    local backup_dir="$1"
    
    debug "Cleaning up old backups (retention: ${RETENTION_DAYS} days)"
    
    # Find and remove backups older than retention period
    find "$backup_dir" -name "${TEAM_NAME}_*.tar*" -type f -mtime +${RETENTION_DAYS} -delete || true
    
    local remaining_backups
    remaining_backups=$(find "$backup_dir" -name "${TEAM_NAME}_*.tar*" -type f | wc -l)
    debug "Remaining backups: $remaining_backups"
}

# Main execution function
main() {
    log "[START] Starting unified data management for ${TEAM_NAME}"
    log "Operation mode: ${OPERATION_MODE}"
    log "Active environment: ${ACTIVE_ENV}"
    
    # Parse arguments and validate configuration
    parse_arguments "$@"
    
    if ! validate_configuration; then
        error "Configuration validation failed"
        exit 1
    fi
    
    if ! check_prerequisites; then
        error "Prerequisites check failed"
        exit 1
    fi
    
    local overall_success=true
    
    # Execute operations based on mode
    case "$OPERATION_MODE" in
        "sync-only")
            if [[ -n "$TARGET_ENV" && "$TARGET_ENV" != "shared" ]]; then
                if ! perform_sync_to_bluegreen; then
                    overall_success=false
                fi
            else
                if ! perform_sync_to_shared; then
                    overall_success=false
                fi
            fi
            
            if [[ "$SYNC_VERIFICATION_ENABLED" == "true" && "$overall_success" == "true" ]]; then
                if ! verify_sync_operation; then
                    overall_success=false
                fi
            fi
            ;;
            
        "backup-only")
            if ! perform_backup; then
                overall_success=false
            fi
            ;;
            
        "sync-and-backup")
            # Parallel execution
            local sync_pid backup_pid
            
            if [[ -n "$TARGET_ENV" && "$TARGET_ENV" != "shared" ]]; then
                perform_sync_to_bluegreen &
                sync_pid=$!
            else
                perform_sync_to_shared &
                sync_pid=$!
            fi
            
            perform_backup &
            backup_pid=$!
            
            # Wait for both operations
            wait $sync_pid || overall_success=false
            wait $backup_pid || overall_success=false
            
            # Verification
            if [[ "$SYNC_VERIFICATION_ENABLED" == "true" && "$overall_success" == "true" ]]; then
                if ! verify_sync_operation; then
                    overall_success=false
                fi
            fi
            ;;
            
        "backup-then-sync")
            # Sequential execution: backup first
            if ! perform_backup; then
                overall_success=false
            fi
            
            if [[ "$overall_success" == "true" ]]; then
                if [[ -n "$TARGET_ENV" && "$TARGET_ENV" != "shared" ]]; then
                    if ! perform_sync_to_bluegreen; then
                        overall_success=false
                    fi
                else
                    if ! perform_sync_to_shared; then
                        overall_success=false
                    fi
                fi
                
                if [[ "$SYNC_VERIFICATION_ENABLED" == "true" && "$overall_success" == "true" ]]; then
                    if ! verify_sync_operation; then
                        overall_success=false
                    fi
                fi
            fi
            ;;
            
        "sync-then-backup")
            # Sequential execution: sync first
            if [[ -n "$TARGET_ENV" && "$TARGET_ENV" != "shared" ]]; then
                if ! perform_sync_to_bluegreen; then
                    overall_success=false
                fi
            else
                if ! perform_sync_to_shared; then
                    overall_success=false
                fi
            fi
            
            if [[ "$SYNC_VERIFICATION_ENABLED" == "true" && "$overall_success" == "true" ]]; then
                if ! verify_sync_operation; then
                    overall_success=false
                fi
            fi
            
            if [[ "$overall_success" == "true" ]]; then
                if ! perform_backup; then
                    overall_success=false
                fi
            fi
            ;;
    esac
    
    # Final status report
    if [[ "$overall_success" == "true" ]]; then
        log "[COMPLETE] Unified data management completed successfully"
        exit 0
    else
        error "[FAILED] Unified data management completed with errors"
        exit 1
    fi
}

# Execute main function with all arguments
main "$@"