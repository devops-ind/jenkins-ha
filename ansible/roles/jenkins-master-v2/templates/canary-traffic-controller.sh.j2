#!/bin/bash
# Canary Traffic Controller for Jenkins HA Infrastructure
# Handles gradual traffic switching with validation during upgrades

set -euo pipefail

# Configuration
TEAM_NAME="{{ item.team_name }}"
JENKINS_HOME="{{ jenkins_home_dir }}"
HAPROXY_STATS_URL="http://{{ groups['load_balancers'][0] }}:{{ haproxy_stats_port }}/stats"
HAPROXY_ADMIN_URL="http://{{ groups['load_balancers'][0] }}:{{ haproxy_admin_port }}"
CONTAINER_RUNTIME="{{ jenkins_master_container_runtime }}"
VALIDATION_TIMEOUT="{{ canary_validation_timeout | default(900) }}"
TRAFFIC_INCREMENT="{{ canary_traffic_increment | default(10) }}"
VALIDATION_INTERVAL="{{ canary_validation_interval | default(60) }}"

# Colors and formatting
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'

# Logging functions
log() { echo -e "${BLUE}[$(date '+%Y-%m-%d %H:%M:%S')]${NC} $1"; }
error() { echo -e "${RED}[ERROR]${NC} $1" >&2; }
success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }
warn() { echo -e "${YELLOW}[WARNING]${NC} $1"; }
info() { echo -e "${CYAN}[INFO]${NC} $1"; }

# Traffic control state
CURRENT_TRAFFIC_SPLIT=0
ROLLBACK_REQUIRED=false
METRICS_BASELINE=""
ERROR_THRESHOLD=5
LATENCY_THRESHOLD=2000

# Display usage
usage() {
    cat << EOF
Usage: $0 [OPTIONS]

OPTIONS:
    --team TEAM                 Team name
    --source-env ENV            Source environment (current active)
    --target-env ENV            Target environment (upgraded)
    --traffic-percent PERCENT   Target traffic percentage for canary
    --validation-script PATH    Custom validation script
    --error-threshold PERCENT   Error rate threshold (default: 5%)
    --latency-threshold MS      Latency threshold in milliseconds (default: 2000ms)
    --increment PERCENT         Traffic increment per step (default: 10%)
    --interval SECONDS          Validation interval (default: 60s)
    --timeout SECONDS           Total validation timeout (default: 900s)
    --auto-rollback             Enable automatic rollback on failure
    --dry-run                   Simulation mode, no actual traffic changes
    --help                      Show this help

EXAMPLES:
    # Gradual canary deployment with 50% target traffic
    $0 --team devops --source-env blue --target-env green --traffic-percent 50
    
    # Conservative canary with custom thresholds
    $0 --team devops --source-env blue --target-env green --traffic-percent 25 \
       --error-threshold 2 --latency-threshold 1500 --increment 5
    
    # Full traffic switch with validation
    $0 --team devops --source-env blue --target-env green --traffic-percent 100 \
       --auto-rollback --timeout 1800

EOF
}

# Parse command line arguments
parse_args() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            --team)
                TEAM_NAME="$2"
                shift 2
                ;;
            --source-env)
                SOURCE_ENV="$2"
                shift 2
                ;;
            --target-env)
                TARGET_ENV="$2"
                shift 2
                ;;
            --traffic-percent)
                TARGET_TRAFFIC_PERCENT="$2"
                shift 2
                ;;
            --validation-script)
                CUSTOM_VALIDATION_SCRIPT="$2"
                shift 2
                ;;
            --error-threshold)
                ERROR_THRESHOLD="$2"
                shift 2
                ;;
            --latency-threshold)
                LATENCY_THRESHOLD="$2"
                shift 2
                ;;
            --increment)
                TRAFFIC_INCREMENT="$2"
                shift 2
                ;;
            --interval)
                VALIDATION_INTERVAL="$2"
                shift 2
                ;;
            --timeout)
                VALIDATION_TIMEOUT="$2"
                shift 2
                ;;
            --auto-rollback)
                AUTO_ROLLBACK=true
                shift
                ;;
            --dry-run)
                DRY_RUN=true
                shift
                ;;
            --help)
                usage
                exit 0
                ;;
            *)
                error "Unknown option: $1"
                usage
                exit 1
                ;;
        esac
    done
    
    # Validate required parameters
    if [[ -z "${SOURCE_ENV:-}" || -z "${TARGET_ENV:-}" ]]; then
        error "Source and target environments are required"
        usage
        exit 1
    fi
    
    if [[ -z "${TARGET_TRAFFIC_PERCENT:-}" ]]; then
        error "Target traffic percentage is required"
        usage
        exit 1
    fi
    
    if [[ "$TARGET_TRAFFIC_PERCENT" -lt 0 || "$TARGET_TRAFFIC_PERCENT" -gt 100 ]]; then
        error "Target traffic percentage must be between 0 and 100"
        exit 1
    fi
}

# Get current HAProxy configuration
get_haproxy_config() {
    log "Retrieving current HAProxy configuration..."
    
    local config_output=$(curl -s "${HAPROXY_STATS_URL};csv" | grep "${TEAM_NAME}" || echo "")
    
    if [[ -z "$config_output" ]]; then
        error "No HAProxy configuration found for team: $TEAM_NAME"
        return 1
    fi
    
    # Parse current backend weights
    local source_weight=$(echo "$config_output" | grep "${TEAM_NAME}-${SOURCE_ENV}" | cut -d',' -f19 || echo "0")
    local target_weight=$(echo "$config_output" | grep "${TEAM_NAME}-${TARGET_ENV}" | cut -d',' -f19 || echo "0")
    
    CURRENT_TRAFFIC_SPLIT=$(( target_weight * 100 / (source_weight + target_weight) ))
    
    log "Current traffic split: ${SOURCE_ENV}=${source_weight}, ${TARGET_ENV}=${target_weight} (${CURRENT_TRAFFIC_SPLIT}% to target)"
}

# Collect baseline metrics
collect_baseline_metrics() {
    log "Collecting baseline metrics..."
    
    local baseline_data=$(cat <<EOF
{
    "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
    "source_environment": "$SOURCE_ENV",
    "target_environment": "$TARGET_ENV",
    "metrics": {
        "error_rate": $(get_error_rate "$SOURCE_ENV"),
        "avg_latency": $(get_avg_latency "$SOURCE_ENV"),
        "throughput": $(get_throughput "$SOURCE_ENV"),
        "active_sessions": $(get_active_sessions "$SOURCE_ENV")
    }
}
EOF
)
    
    METRICS_BASELINE="$baseline_data"
    info "Baseline metrics collected for $SOURCE_ENV"
}

# Get error rate for environment
get_error_rate() {
    local env="$1"
    local container_name="jenkins-${TEAM_NAME}-${env}"
    
    # Query Jenkins metrics API or log analysis
    local error_count=$($CONTAINER_RUNTIME exec "$container_name" \
        grep -c "ERROR" /var/jenkins_home/logs/jenkins.log 2>/dev/null | tail -100 || echo "0")
    local total_requests=$($CONTAINER_RUNTIME exec "$container_name" \
        grep -c "completed" /var/jenkins_home/logs/jenkins.log 2>/dev/null | tail -1000 || echo "1")
    
    echo "scale=2; $error_count * 100 / $total_requests" | bc -l 2>/dev/null || echo "0"
}

# Get average latency for environment
get_avg_latency() {
    local env="$1"
    local web_port
    
    if [[ "$env" == "blue" ]]; then
        web_port="{{ item.ports.web }}"
    else
        web_port="{{ item.ports.web_green | default(item.ports.web | int + 1000) }}"
    fi
    
    # Use curl to measure response time
    local response_time=$(curl -w "%{time_total}" -s -o /dev/null \
        "http://localhost:${web_port}/api/json" 2>/dev/null || echo "999")
    
    echo "scale=0; $response_time * 1000" | bc -l 2>/dev/null || echo "999"
}

# Get throughput for environment
get_throughput() {
    local env="$1"
    local container_name="jenkins-${TEAM_NAME}-${env}"
    
    # Count requests in last minute
    local current_time=$(date +%s)
    local minute_ago=$((current_time - 60))
    
    $CONTAINER_RUNTIME exec "$container_name" \
        awk -v start="$minute_ago" '
        {
            if ($4 >= start) count++
        }
        END { print count+0 }
        ' /var/jenkins_home/logs/access.log 2>/dev/null || echo "0"
}

# Get active sessions for environment
get_active_sessions() {
    local env="$1"
    local web_port
    
    if [[ "$env" == "blue" ]]; then
        web_port="{{ item.ports.web }}"
    else
        web_port="{{ item.ports.web_green | default(item.ports.web | int + 1000) }}"
    fi
    
    # Query Jenkins API for active sessions
    curl -s "http://localhost:${web_port}/manage/system-info/api/json" 2>/dev/null | \
        jq '.activeSessionCount // 0' 2>/dev/null || echo "0"
}

# Update HAProxy backend weights
update_traffic_split() {
    local target_percent="$1"
    local source_percent=$((100 - target_percent))
    
    log "Updating traffic split: ${SOURCE_ENV}=${source_percent}%, ${TARGET_ENV}=${target_percent}%"
    
    if [[ "${DRY_RUN:-false}" == "true" ]]; then
        info "[DRY RUN] Would update HAProxy weights: ${SOURCE_ENV}=${source_percent}, ${TARGET_ENV}=${target_percent}"
        return 0
    fi
    
    # Update source environment weight
    local source_result=$(curl -s -X POST \
        "${HAPROXY_ADMIN_URL}/v2/services/haproxy/configuration/servers/${TEAM_NAME}-${SOURCE_ENV}" \
        -H "Content-Type: application/json" \
        -d "{\"weight\": $source_percent}" || echo "ERROR")
    
    # Update target environment weight
    local target_result=$(curl -s -X POST \
        "${HAPROXY_ADMIN_URL}/v2/services/haproxy/configuration/servers/${TEAM_NAME}-${TARGET_ENV}" \
        -H "Content-Type: application/json" \
        -d "{\"weight\": $target_percent}" || echo "ERROR")
    
    if [[ "$source_result" == *"ERROR"* || "$target_result" == *"ERROR"* ]]; then
        error "Failed to update HAProxy configuration"
        return 1
    fi
    
    CURRENT_TRAFFIC_SPLIT="$target_percent"
    success "Traffic split updated successfully"
}

# Validate environment health
validate_environment_health() {
    local env="$1"
    
    log "Validating health for environment: $env"
    
    # Run custom validation script if provided
    if [[ -n "${CUSTOM_VALIDATION_SCRIPT:-}" && -f "$CUSTOM_VALIDATION_SCRIPT" ]]; then
        if ! bash "$CUSTOM_VALIDATION_SCRIPT" --team "$TEAM_NAME" --environment "$env"; then
            error "Custom validation script failed for $env"
            return 1
        fi
    fi
    
    # Basic health checks
    local container_name="jenkins-${TEAM_NAME}-${env}"
    local web_port
    
    if [[ "$env" == "blue" ]]; then
        web_port="{{ item.ports.web }}"
    else
        web_port="{{ item.ports.web_green | default(item.ports.web | int + 1000) }}"
    fi
    
    # Container health
    if ! $CONTAINER_RUNTIME inspect "$container_name" --format='{{.State.Status}}' | grep -q "running"; then
        error "Container $container_name is not running"
        return 1
    fi
    
    # Web interface health
    if ! curl -f -s --max-time 10 "http://localhost:${web_port}/login" >/dev/null; then
        error "Web interface not accessible for $env"
        return 1
    fi
    
    # API health
    if ! curl -f -s --max-time 10 "http://localhost:${web_port}/api/json" >/dev/null; then
        error "API not accessible for $env"
        return 1
    fi
    
    success "Environment $env health validation passed"
    return 0
}

# Validate metrics against thresholds
validate_metrics() {
    local env="$1"
    
    log "Validating metrics for environment: $env"
    
    local current_error_rate=$(get_error_rate "$env")
    local current_latency=$(get_avg_latency "$env")
    
    info "Current metrics - Error Rate: ${current_error_rate}%, Latency: ${current_latency}ms"
    
    # Check error rate threshold
    if (( $(echo "$current_error_rate > $ERROR_THRESHOLD" | bc -l) )); then
        error "Error rate ${current_error_rate}% exceeds threshold ${ERROR_THRESHOLD}%"
        return 1
    fi
    
    # Check latency threshold
    if (( $(echo "$current_latency > $LATENCY_THRESHOLD" | bc -l) )); then
        error "Latency ${current_latency}ms exceeds threshold ${LATENCY_THRESHOLD}ms"
        return 1
    fi
    
    success "Metrics validation passed for $env"
    return 0
}

# Rollback traffic to source environment
rollback_traffic() {
    warn "Initiating traffic rollback to $SOURCE_ENV"
    
    if update_traffic_split 0; then
        success "Traffic successfully rolled back to $SOURCE_ENV"
        
        # Wait for rollback to take effect
        sleep 30
        
        # Validate rollback
        if validate_environment_health "$SOURCE_ENV" && validate_metrics "$SOURCE_ENV"; then
            success "Rollback validation successful"
        else
            error "Rollback validation failed - manual intervention required"
        fi
    else
        error "Failed to rollback traffic - manual intervention required"
    fi
}

# Execute canary deployment
execute_canary_deployment() {
    log "Starting canary deployment: ${SOURCE_ENV} → ${TARGET_ENV}"
    info "Target traffic: ${TARGET_TRAFFIC_PERCENT}%, Increment: ${TRAFFIC_INCREMENT}%, Interval: ${VALIDATION_INTERVAL}s"
    
    local start_time=$(date +%s)
    local current_percent="$CURRENT_TRAFFIC_SPLIT"
    
    while [[ "$current_percent" -lt "$TARGET_TRAFFIC_PERCENT" ]]; do
        # Calculate next increment
        local next_percent=$((current_percent + TRAFFIC_INCREMENT))
        if [[ "$next_percent" -gt "$TARGET_TRAFFIC_PERCENT" ]]; then
            next_percent="$TARGET_TRAFFIC_PERCENT"
        fi
        
        log "Incrementing traffic to ${TARGET_ENV}: ${next_percent}%"
        
        # Update traffic split
        if ! update_traffic_split "$next_percent"; then
            error "Failed to update traffic split"
            if [[ "${AUTO_ROLLBACK:-false}" == "true" ]]; then
                rollback_traffic
            fi
            return 1
        fi
        
        # Wait for traffic change to take effect
        sleep 15
        
        # Validate target environment health
        if ! validate_environment_health "$TARGET_ENV"; then
            error "Target environment health check failed"
            if [[ "${AUTO_ROLLBACK:-false}" == "true" ]]; then
                rollback_traffic
            fi
            return 1
        fi
        
        # Wait for metrics collection interval
        sleep "$VALIDATION_INTERVAL"
        
        # Validate metrics
        if ! validate_metrics "$TARGET_ENV"; then
            error "Target environment metrics validation failed"
            if [[ "${AUTO_ROLLBACK:-false}" == "true" ]]; then
                rollback_traffic
            fi
            return 1
        fi
        
        current_percent="$next_percent"
        
        # Check timeout
        local current_time=$(date +%s)
        local elapsed=$((current_time - start_time))
        if [[ "$elapsed" -gt "$VALIDATION_TIMEOUT" ]]; then
            error "Canary deployment timeout reached (${VALIDATION_TIMEOUT}s)"
            if [[ "${AUTO_ROLLBACK:-false}" == "true" ]]; then
                rollback_traffic
            fi
            return 1
        fi
        
        success "Traffic increment to ${next_percent}% successful"
    done
    
    success "Canary deployment completed successfully!"
    info "Final traffic split: ${SOURCE_ENV}=$((100 - TARGET_TRAFFIC_PERCENT))%, ${TARGET_ENV}=${TARGET_TRAFFIC_PERCENT}%"
    
    # Generate deployment report
    generate_deployment_report
}

# Generate deployment report
generate_deployment_report() {
    local end_time=$(date -u +%Y-%m-%dT%H:%M:%SZ)
    local final_error_rate=$(get_error_rate "$TARGET_ENV")
    local final_latency=$(get_avg_latency "$TARGET_ENV")
    local final_throughput=$(get_throughput "$TARGET_ENV")
    
    cat <<EOF > "/tmp/canary-deployment-report-${TEAM_NAME}-$(date +%s).json"
{
    "deployment_summary": {
        "team": "$TEAM_NAME",
        "source_environment": "$SOURCE_ENV",
        "target_environment": "$TARGET_ENV",
        "target_traffic_percent": $TARGET_TRAFFIC_PERCENT,
        "traffic_increment": $TRAFFIC_INCREMENT,
        "validation_interval": $VALIDATION_INTERVAL,
        "deployment_successful": true,
        "end_timestamp": "$end_time"
    },
    "baseline_metrics": $METRICS_BASELINE,
    "final_metrics": {
        "error_rate": $final_error_rate,
        "avg_latency": $final_latency,
        "throughput": $final_throughput
    },
    "thresholds": {
        "error_threshold": $ERROR_THRESHOLD,
        "latency_threshold": $LATENCY_THRESHOLD
    }
}
EOF
    
    success "Deployment report generated: /tmp/canary-deployment-report-${TEAM_NAME}-$(date +%s).json"
}

# Main execution function
main() {
    parse_args "$@"
    
    log "Starting canary traffic controller for team: $TEAM_NAME"
    info "Configuration: ${SOURCE_ENV} → ${TARGET_ENV} (${TARGET_TRAFFIC_PERCENT}%)"
    
    # Initialize
    get_haproxy_config || exit 1
    collect_baseline_metrics
    
    # Pre-deployment validation
    log "Performing pre-deployment validation..."
    validate_environment_health "$SOURCE_ENV" || exit 1
    validate_environment_health "$TARGET_ENV" || exit 1
    
    # Execute canary deployment
    execute_canary_deployment
    
    success "Canary traffic controller completed successfully!"
}

# Handle script termination
trap 'error "Canary deployment interrupted"; if [[ "${AUTO_ROLLBACK:-false}" == "true" ]]; then rollback_traffic; fi; exit 130' INT TERM

# Execute main function if script is run directly
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi